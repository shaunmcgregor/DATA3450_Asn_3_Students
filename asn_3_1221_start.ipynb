{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import thinkplot\n",
    "#import thinkstats2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.stats as ss\n",
    "import thinkplot\n",
    "import thinkstats2\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "##Seaborn for fancy plots. \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "#need a fork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - Basic Predictions and Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "### Part 1 - Election Prediction\n",
    "\n",
    "Suppose you are looking at an election in a fictional province. There are 7 total elctoral districts, and the winner in each district is determined by a first-past-the-post system (what we have in Canada - the most votes wins, regardless of share). There are two parties - the Purples and the Yellows. Whoever controls the most seats will be the ruling party - so in our 2 party scenario, the party who wins 4 or more of the districts will govern. There is an election every year, they love voting. \n",
    "\n",
    "Recent polling indicating the expected vote share in each district is shown in the \"dist_polls\" table below. These values are a composite of several polls that the experts have combined and weighted. The \"Purple\" values show the expected vote share of the Purple party, along with the variance of that expectation and the number of polls that were combined to get that result.  \n",
    "\n",
    "As well, research has shown that the vote distribution is impacted by voter turnout. In general, the more people vote, the more the vote split shifts towards the Yellow party. We have data on past elections and the results, we expect that the turnout will be in line with the past elections - or more specifically, we have no reason to expect it to differ. This impact is measured in the table in code below - that table shows the voter turnout, in a percentage, as well as the change in the Yellow party's vote share (also in percentage) as compared to the polling averages. For example, if one row showed \"52\" and \".8\", that would mean that voter turnout was 52%, and the Yellow party got .8% higher of a vote share than the polling showed. \n",
    "\n",
    "<b>What is the probability that the Purple Party controls the government after the election?</b>\n",
    "\n",
    "<b>Note:</b> the errors and confidence intervals are not totally trivial. As part of the written answer, offer an evaluation of your confidence in the prediction, and why you think that. This is not a question with one specific error, your estimation will have some expected errors, somewhere. You may not have the tools to calculate it all the way through, that's fine. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 - Your Answer in English\n",
    "\n",
    "Please fill in (and extend if required) the list here to explain what you did. There are multiple reasonable things you could do to approach this, so please note what you did here. For most people I assume this will be about 3-5 statements - you don't need to explain the internals of things we covered (e.g. if there's a hypothesis test, you don't need to explain how that works), just how you structured your approach to the problem. \n",
    "\n",
    "<ul>\n",
    "<li>Use a linear regression to predict the \"yellow improvement\" if the voter turnout is 60%\n",
    "<li>Take the mean of the poll results per distrit and use that as the probability of getting a vote for purple\n",
    "<li>Add the \"yellow improvement\" to the proportion that purple needs to win, i.e. purple needs 53.7% of the vote to win a district as the yellow improvement is 3.7%\n",
    "<li>Simulate the election in all 7 districts (aparently 1 million times, becouse I'm bad at math)\n",
    "<li>check to see how many districts purple wins the majority of the time (2) and decide they aren't forming government if the turnout is 60%\n",
    "<li> <b> What do you think about the error/accuracy:</b> the RMSE was about 1.6% across all districts, this brings a few CIs to include the win % of 53.7 which makes me think this isn't as clear cut of a loss as it seems. I also didn't love getting the mean of the polling, I thought that it wasn't quite right but the other way I tried it (random value between lowest poll amount and highest poll amount) created too much variation in results. If I had more time I might find a way to randomly select a specific poll and use those numbers instead of the mean. CI of 6% also seem high to me there is a big difference between getting 51% of the vote and getting 57% of the vote.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup Poll Data\n",
    "\n",
    "The dataframe \"dist_polls\" contains all of the polls for each seat. Each value is expressed as expected vote share (as a ratio) for the <b>Purple</b> party. The Yellow party can be safely assumed to get the rest of the votes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "      <th>Poll_1</th>\n",
       "      <th>Poll_2</th>\n",
       "      <th>Poll_3</th>\n",
       "      <th>Poll_4</th>\n",
       "      <th>Poll_5</th>\n",
       "      <th>Poll_6</th>\n",
       "      <th>Poll_7</th>\n",
       "      <th>Poll_8</th>\n",
       "      <th>Poll_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   district  Poll_1  Poll_2  Poll_3  Poll_4  Poll_5  Poll_6  Poll_7  Poll_8  \\\n",
       "0         1    0.55    0.53    0.51    0.47    0.61    0.54    0.55    0.53   \n",
       "1         2    0.49    0.51    0.49    0.48    0.52    0.45    0.47    0.49   \n",
       "2         3    0.51    0.51    0.53    0.51    0.49    0.51    0.50    0.51   \n",
       "3         4    0.60    0.62    0.61    0.54    0.73    0.61    0.56    0.55   \n",
       "4         5    0.41    0.44    0.42    0.45    0.44    0.47    0.47    0.43   \n",
       "\n",
       "   Poll_9  \n",
       "0    0.57  \n",
       "1    0.39  \n",
       "2    0.52  \n",
       "3    0.57  \n",
       "4    0.53  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please don't edit this part. \n",
    "# Setup polling data. \n",
    "districts = [1,2,3,4,5,6,7]\n",
    "dist_polls = pd.DataFrame(districts, columns={\"district\"})\n",
    "\n",
    "dist_polls[\"Poll_1\"] = [.55, .49, .51, .6, .41, .46, .54]\n",
    "dist_polls[\"Poll_2\"] = [.53, .51, .51, .62, .44, .48, .53]\n",
    "dist_polls[\"Poll_3\"] = [.51, .49, .53, .61, .42, .46, .52]\n",
    "dist_polls[\"Poll_4\"] = [.47, .48, .51, .54, .45, .45, .51]\n",
    "dist_polls[\"Poll_5\"] = [.61, .52, .49, .73, .44, .51, .53]\n",
    "dist_polls[\"Poll_6\"] = [.54, .45, .51, .61, .47, .52, .52]\n",
    "dist_polls[\"Poll_7\"] = [.55, .47, .5, .56, .47, .46, .56]\n",
    "dist_polls[\"Poll_8\"] = [.53, .49, .51, .55, .43, .49, .55]\n",
    "dist_polls[\"Poll_9\"] = [.57, .39, .52, .57, .53, .43, .53]\n",
    "\n",
    "\n",
    "dist_polls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup Turnout Data\n",
    "\n",
    "The dataframe \"past_vte_table\" shows the voter turnout, along with the impact on the votes counted for the <b>Yellow party</b>, all expressed as percentages. For example, if in one row the turnout is .45 and the Yellow_improvement is -.04, that means that 45% of the populace turned out to vote, and the Yellow party got 4% fewer votes than polling indicated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>voter_turn_percentage</th>\n",
       "      <th>Yellow_improvement</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.012</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.023</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.48</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.031</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.030</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   voter_turn_percentage  Yellow_improvement  year\n",
       "0                   0.53               0.012  2013\n",
       "1                   0.51               0.023  2014\n",
       "2                   0.48              -0.017  2015\n",
       "3                   0.55               0.031  2016\n",
       "4                   0.54               0.030  2017"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please don't edit this part. \n",
    "# Setup vote data. \n",
    "voter_turnout_history = [.53, .51, .48, .55, .54, .59, .49, .57, .56]\n",
    "past_vote_table = pd.DataFrame(voter_turnout_history, columns={\"voter_turn_percentage\"})\n",
    "past_vote_table[\"Yellow_improvement\"] = [.012, .023, -.017, .031, .030, -.004, -.03, .042, .029]\n",
    "past_vote_table[\"year\"] = [2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021]\n",
    "past_vote_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Your Work\n",
    "\n",
    "### Part 1 - Election"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three functions that help me simulate the election 1000 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets samples, based on vote probability for 1000 simulations\n",
    "def getSample(voteProb, n=1000):\n",
    "    vote_list = []\n",
    "    for i in range(n):\n",
    "        vote_list.append(np.random.binomial(n=1, p=voteProb))\n",
    "    return vote_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the means list, rmse, cdf object and ci for 1000 runs of one district\n",
    "def simulateDistrictElection(voteProb,times = 100):\n",
    "    meanList = []\n",
    "    for i in range(times):\n",
    "        meanList.append(np.mean(getSample(voteProb, times)))\n",
    "    muList = [voteProb] * times\n",
    "    cdf = thinkstats2.Cdf(meanList) #Make a CDF of the means of the analytical dist's\n",
    "    ci = cdf.Percentile(2.5), cdf.Percentile(97.5) #5th, 95th percentiles. \n",
    "    stderr = mean_squared_error(meanList, muList, squared=False)\n",
    "    return meanList, stderr, cdf, ci\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulates all 7 districs 1000 times with the mean of the polling for that district and calculates the percentage of wins for purple in those 1000 trials\n",
    "def simulateAll(piv, yellowImprovement, trials = 1000):\n",
    "    returnArray = []\n",
    "    amountToWin = .5 + yellowImprovement\n",
    "    for column in piv.columns:\n",
    "        means, err, cdf, ci = simulateDistrictElection(piv[column].mean(), trials)\n",
    "        purpWins = 0\n",
    "        for i in range(len(means)):\n",
    "            if means[i] > amountToWin:\n",
    "                purpWins = purpWins + 1\n",
    "        #add it to the return array\n",
    "        returnArray.append([column + 1, means, err, cdf, ci, (purpWins/trials)])\n",
    "    return returnArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Poll_1</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Poll_2</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Poll_3</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Poll_4</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Poll_5</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1     2     3     4     5     6\n",
       "Poll_1  0.55  0.49  0.51  0.60  0.41  0.46  0.54\n",
       "Poll_2  0.53  0.51  0.51  0.62  0.44  0.48  0.53\n",
       "Poll_3  0.51  0.49  0.53  0.61  0.42  0.46  0.52\n",
       "Poll_4  0.47  0.48  0.51  0.54  0.45  0.45  0.51\n",
       "Poll_5  0.61  0.52  0.49  0.73  0.44  0.51  0.53"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#do a pivot here to make getting the mean of the polls easier\n",
    "piv = dist_polls.T\n",
    "piv = piv.drop(axis=0, index={\"district\"})\n",
    "piv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the improvement for yellow if the voter turnout is 60%\n",
    "x = np.array(past_vote_table[\"Yellow_improvement\"]).reshape(-1,1)\n",
    "y = np.array(past_vote_table[\"voter_turn_percentage\"]).reshape(-1,1)\n",
    "\n",
    "model = LinearRegression().fit(y, x)\n",
    "pred = model.predict(np.array(0.60).reshape(-1,1))\n",
    "yellowImprovement = pred[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate the election in all 7 districts 1000 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = simulateAll(piv, yellowImprovement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "district 1 : percent of scenarios where purple wins:56.5%\n",
      "district 1 : 95% confidence that purple gets 51.1% and 57.0% percent of the vote +/- 1.5%\n",
      "\n",
      "\n",
      "district 2 : percent of scenarios where purple wins:0.1%\n",
      "district 2 : 95% confidence that purple gets 44.5% and 50.9% percent of the vote +/- 1.6%\n",
      "\n",
      "\n",
      "district 3 : percent of scenarios where purple wins:4.0%\n",
      "district 3 : 95% confidence that purple gets 47.9% and 54.0% percent of the vote +/- 1.6%\n",
      "\n",
      "\n",
      "district 4 : percent of scenarios where purple wins:100.0%\n",
      "district 4 : 95% confidence that purple gets 56.7% and 63.1% percent of the vote +/- 1.6%\n",
      "\n",
      "\n",
      "district 5 : percent of scenarios where purple wins:0.0%\n",
      "district 5 : 95% confidence that purple gets 41.9% and 47.9% percent of the vote +/- 1.5%\n",
      "\n",
      "\n",
      "district 6 : percent of scenarios where purple wins:0.0%\n",
      "district 6 : 95% confidence that purple gets 44.1% and 50.3% percent of the vote +/- 1.6%\n",
      "\n",
      "\n",
      "district 7 : percent of scenarios where purple wins:36.2%\n",
      "district 7 : 95% confidence that purple gets 50.1% and 56.2% percent of the vote +/- 1.5%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numOfPurpWins = 0\n",
    "for result in results:\n",
    "    if result[5] > .5:\n",
    "        numOfPurpWins = numOfPurpWins + 1\n",
    "    print(\"district\",result[0], \": percent of scenarios where purple wins:%.1f%%\" % (result[5] * 100))\n",
    "    print(\"district\", result[0], \": 95%% confidence that purple gets %.1f%% and %.1f%% percent of the vote\" % (result[4][0]*100, result[4][1]*100), \"+/- %.1f%%\" % (result[2]*100))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability that purple wins the election with 60% voter turnout is 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Regression\n",
    "\n",
    "<b>Use the data provided to try to predict the wage. </b>\n",
    "\n",
    "The data is from FIFA rankings for players. You don't need to know anything about soccer or video games for this, so if these values are meaningless to you, just treat them as numbers and you'll be fine. All of the features are rankings are evaluations of how good different soccar players are at different skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer in English\n",
    "\n",
    "Please fill in (and extend if required) the list here to explain what you did. There are multiple reasonable things you could do to approach this, so please note what you did here. For most people I assume this will be about 3-5 statements - you don't need to explain the internals of things we covered (e.g. if there's a hypothesis test, you don't need to explain how that works), just how you structured your approach to the problem. \n",
    "\n",
    "<ul>\n",
    "<li>\n",
    "<li>\n",
    "<li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"players_20_2.csv\")\n",
    "df.head()\n",
    "\n",
    "#remove outliers\n",
    "df = df[df[\"wage_eur\"] > 0]\n",
    "df = df[df[\"wage_eur\"] < 80000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- multivariant poly??\n",
    "- log the wage?\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    17781.000000\n",
       "mean      7651.200720\n",
       "std      11580.390379\n",
       "min       1000.000000\n",
       "25%       1000.000000\n",
       "50%       3000.000000\n",
       "75%       8000.000000\n",
       "max      79000.000000\n",
       "Name: wage_eur, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sns.pairplot(df)\n",
    "# sns.histplot(df[\"wage_eur\"])\n",
    "\n",
    "\n",
    "\n",
    "# df=pd.get_dummies(df,)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# sns.histplot(df[\"wage_eur\"], stat=\"density\", kde=True)\n",
    "# plt.show()\n",
    "# df[\"logWage\"] = np.log10(df[\"wage_eur\"])\n",
    "\n",
    "# sns.histplot(df[\"logWage\"],  stat=\"density\", kde=True)\n",
    "df[\"wage_eur\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.36551103704902, 9300.885137962678)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Multiple Linear Regression\n",
    "y = np.array(df[\"wage_eur\"]).reshape(-1,1)\n",
    "x = np.array(df.drop(columns={\"wage_eur\"}))\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x,y,test_size=.3)\n",
    "model = LinearRegression().fit(xTrain,yTrain)\n",
    "pred = model.predict(xTest)\n",
    "rmse = mean_squared_error(pred, yTest, squared=False)\n",
    "r_sq = model.score(xTest,yTest)\n",
    "\n",
    "r_sq, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "White hot garbage, we need some curves in this linear world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.42 GiB for an array with shape (17781, 40920) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Shaun\\Documents\\Data Analytics\\3450\\DATA3450_Asn_3_Students\\asn_3_1221_start.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Shaun/Documents/Data%20Analytics/3450/DATA3450_Asn_3_Students/asn_3_1221_start.ipynb#X61sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# power = PowerTransformer(method= \"box-cox\")\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Shaun/Documents/Data%20Analytics/3450/DATA3450_Asn_3_Students/asn_3_1221_start.ipynb#X61sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# quant = QuantileTransformer(output_distribution='normal', random_state=0)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Shaun/Documents/Data%20Analytics/3450/DATA3450_Asn_3_Students/asn_3_1221_start.ipynb#X61sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# sns.histplot(power.fit_transform(df[\"wage_eur\"]).reshape(1,-1))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Shaun/Documents/Data%20Analytics/3450/DATA3450_Asn_3_Students/asn_3_1221_start.ipynb#X61sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m m2 \u001b[39m=\u001b[39m make_pipeline(poly, LinearRegression())\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Shaun/Documents/Data%20Analytics/3450/DATA3450_Asn_3_Students/asn_3_1221_start.ipynb#X61sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m m2\u001b[39m.\u001b[39;49mfit(x,y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Shaun/Documents/Data%20Analytics/3450/DATA3450_Asn_3_Students/asn_3_1221_start.ipynb#X61sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m ypred \u001b[39m=\u001b[39m m2\u001b[39m.\u001b[39mpredict(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Shaun/Documents/Data%20Analytics/3450/DATA3450_Asn_3_Students/asn_3_1221_start.ipynb#X61sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m rmseButCurved \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(mean_squared_error(y,ypred))\n",
      "File \u001b[1;32mc:\\Users\\Shaun\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:382\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    381\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 382\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    384\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Shaun\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:692\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    684\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[0;32m    685\u001b[0m     X, y, accept_sparse\u001b[39m=\u001b[39maccept_sparse, y_numeric\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, multi_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    686\u001b[0m )\n\u001b[0;32m    688\u001b[0m sample_weight \u001b[39m=\u001b[39m _check_sample_weight(\n\u001b[0;32m    689\u001b[0m     sample_weight, X, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype, only_non_negative\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    690\u001b[0m )\n\u001b[1;32m--> 692\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[39m=\u001b[39m _preprocess_data(\n\u001b[0;32m    693\u001b[0m     X,\n\u001b[0;32m    694\u001b[0m     y,\n\u001b[0;32m    695\u001b[0m     fit_intercept\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[0;32m    696\u001b[0m     normalize\u001b[39m=\u001b[39;49m_normalize,\n\u001b[0;32m    697\u001b[0m     copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy_X,\n\u001b[0;32m    698\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    699\u001b[0m )\n\u001b[0;32m    701\u001b[0m \u001b[39m# Sample weight can be implemented via a simple rescaling.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m X, y, sample_weight_sqrt \u001b[39m=\u001b[39m _rescale_data(X, y, sample_weight)\n",
      "File \u001b[1;32mc:\\Users\\Shaun\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:262\u001b[0m, in \u001b[0;36m_preprocess_data\u001b[1;34m(X, y, fit_intercept, normalize, copy, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    259\u001b[0m     sample_weight \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(sample_weight)\n\u001b[0;32m    261\u001b[0m \u001b[39mif\u001b[39;00m check_input:\n\u001b[1;32m--> 262\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, copy\u001b[39m=\u001b[39;49mcopy, accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m], dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES)\n\u001b[0;32m    263\u001b[0m \u001b[39melif\u001b[39;00m copy:\n\u001b[0;32m    264\u001b[0m     \u001b[39mif\u001b[39;00m sp\u001b[39m.\u001b[39missparse(X):\n",
      "File \u001b[1;32mc:\\Users\\Shaun\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:925\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    918\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    919\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m feature(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    920\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m a minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    921\u001b[0m             \u001b[39m%\u001b[39m (n_features, array\u001b[39m.\u001b[39mshape, ensure_min_features, context)\n\u001b[0;32m    922\u001b[0m         )\n\u001b[0;32m    924\u001b[0m \u001b[39mif\u001b[39;00m copy \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39mmay_share_memory(array, array_orig):\n\u001b[1;32m--> 925\u001b[0m     array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(array, dtype\u001b[39m=\u001b[39;49mdtype, order\u001b[39m=\u001b[39;49morder)\n\u001b[0;32m    927\u001b[0m \u001b[39mreturn\u001b[39;00m array\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 5.42 GiB for an array with shape (17781, 40920) and data type float64"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "poly = PolynomialFeatures(degree=4)\n",
    "# power = PowerTransformer(method= \"box-cox\")\n",
    "# quant = QuantileTransformer(output_distribution='normal', random_state=0)\n",
    "# sns.histplot(power.fit_transform(df[\"wage_eur\"]).reshape(1,-1))\n",
    "\n",
    "m2 = make_pipeline(poly, LinearRegression())\n",
    "m2.fit(x,y)\n",
    "ypred = m2.predict(x)\n",
    "rmseButCurved = np.sqrt(mean_squared_error(y,ypred))\n",
    "r2ButCurved = m2.score(x,y)\n",
    "print(r2ButCurved) \n",
    "print(rmseButCurved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll take it, .74 R2 and an error of, basically 1/2 a standard deviation...."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8db638d3b940bd10adfd3e31b9d30944957c89679bddca81ff9d9cb86f7e1de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
